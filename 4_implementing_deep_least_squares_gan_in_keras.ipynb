{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-implementing-deep-least-squares-gan-in-keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMcjzxTTMDNGO+9LIfGySMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-deep-learning-with-tensorflow-2-and-keras/blob/4-generative-adversarial-networks/4_implementing_deep_least_squares_gan_in_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFRa3V41yXCB",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Least-squares GAN in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgGCA-ERy4cQ",
        "colab_type": "text"
      },
      "source": [
        "We will implement a GAN that learns to produce realistic-looking handwritten digits. We will use the Python neural network library Keras with a TensorFlow backend.\n",
        "\n",
        "Over the course of the training iterations, the Generator learns to turn random noise input into images that look like members of the training data: the MNIST dataset of handwritten digits. \n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/gans-in-action/gan-network.png?raw=1' width='800'/>\n",
        "\n",
        "Simultaneously, the Discriminator learns to distinguish the fake images produced by the Generator from the genuine ones coming from the training dataset.\n",
        "\n",
        "In deep learning, both the generator and discriminator can be implemented using\n",
        "a suitable neural network architecture. If the data or signal is an image, both the generator and discriminator networks will use a CNN. For single-dimensional\n",
        "sequences such as audio, both networks are usually recurrent (RNN, LSTM, or GRU).\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/dcgan-model.png?raw=1' width='800'/>\n",
        "\n",
        "DCGAN implements the following design principles:\n",
        "\n",
        "* Use strides > 1, and a convolution instead of MaxPooling2D or UpSampling2D.\n",
        "With strides > 1, the CNN learns how to resize the feature maps.\n",
        "\n",
        "* Avoid using Dense layers. **Use CNN in all layers**. The Dense layer is utilized only as the first layer of the generator to accept the z-vector. The output of the Dense layer is resized and becomes the input of the succeeding CNN\n",
        "layers.\n",
        "\n",
        "* Use **Batch Normalization (BN)** to stabilize learning by normalizing the input to each layer to have zero mean and unit variance. There is no BN in the\n",
        "generator output layer and discriminator input layer. In the implementation\n",
        "example to be presented here, no batch normalization is used in the\n",
        "discriminator.\n",
        "\n",
        "* **Rectified Linear Unit (ReLU)** is used in all layers of the generator except in the output layer, where the tanh activation is utilized. In the implementation example to be presented here, sigmoid is used instead of tanh in the output of the generator since it generally results in more stable training for MNIST digits.\n",
        "\n",
        "* **Rectified Linear Unit (ReLU)** is used in all layers of the generator except in the output layer, where the tanh activation is utilized. In the implementation example to be presented here, sigmoid is used instead of tanh in the output of the generator since it generally results in more stable training for MNIST digits.\n",
        "\n",
        "* Use **Leaky ReLU** in all layers of the discriminator. Unlike ReLU, instead\n",
        "of zeroing out all outputs when the input is less than zero, Leaky ReLU\n",
        "generates a small gradient equal to alpha x input. In the following example,\n",
        "alpha = 0.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16cMAR3jolN",
        "colab_type": "text"
      },
      "source": [
        "## LSGAN implementation using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F11jo0Gkjo7-",
        "colab_type": "text"
      },
      "source": [
        "LSGAN proposes the least squares loss. It demonstrates why the use of\n",
        "a sigmoid cross-entropy loss in GANs results in poorly generated data quality:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/LSGAN.png?raw=1' width='800'/>\n",
        "\n",
        "Ideally, the fake sample distribution should be as close as possible to the true\n",
        "samples' distribution. However, for GANs, once the fake samples are already on\n",
        "the correct side of the decision boundary, the gradients vanish.\n",
        "\n",
        "This prevents the generator from having enough motivation to improve the\n",
        "quality of the generated fake data. Fake samples far from the decision boundary\n",
        "will no longer attempt to move closer to the true samples' distribution.\n",
        "\n",
        "Using the least squares loss function, the gradients do not vanish as long as the fake sample distribution is far from the real samples' distribution. The generator will strive to improve its estimate of real density distribution even if the fake samples are already on the correct side of the decision boundary.\n",
        "\n",
        "Both the discriminator and adversarial loss functions are replaced by mse. All the network parameters are the same as in DCGAN. The network model of LSGAN\n",
        "in tf.keras is similar to WGAN except that there is linear or no output\n",
        "activation. The training process is similar to that seen in DCGAN and is provided by the utility function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMFaRsxq0Dcq",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ripW-zhr0Erm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.datasets import  mnist\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kODT4P_oGJsm",
        "colab_type": "text"
      },
      "source": [
        "##  Implementing the Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQxZmD8hGHMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(inputs, image_size, activation='sigmoid', labels=None, codes=None):\n",
        "\n",
        "    image_resize = image_size // 4\n",
        "    # network parameters\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "    if labels is not None:\n",
        "        if codes is None:\n",
        "            # ACGAN labels\n",
        "            # concatenate z noise vector and one-hot labels\n",
        "            inputs = [inputs, labels]\n",
        "        else:\n",
        "            # infoGAN codes\n",
        "            # concatenate z noise vector, \n",
        "            # one-hot labels and codes 1 & 2\n",
        "            inputs = [inputs, labels] + codes\n",
        "        x = concatenate(inputs, axis=1)\n",
        "    elif codes is not None:\n",
        "        # generator 0 of StackedGAN\n",
        "        inputs = [inputs, codes]\n",
        "        x = concatenate(inputs, axis=1)\n",
        "    else:\n",
        "        # default input is just 100-dim noise (z-code)\n",
        "        x = inputs\n",
        "\n",
        "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
        "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "    for filters in layer_filters:\n",
        "        # first two convolution layers use strides = 2\n",
        "        # the last two use strides = 1\n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same')(x)\n",
        "\n",
        "    if activation is not None:\n",
        "        x = Activation(activation)(x)\n",
        "\n",
        "    # generator output is the synthesized image x\n",
        "    return Model(inputs, x, name='generator')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srEYzgpMH4cX",
        "colab_type": "text"
      },
      "source": [
        "## Implementing the Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0oe05jiHyVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(inputs, activation='sigmoid', num_labels=None, num_codes=None):\n",
        "    \n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "    x = inputs\n",
        "    for filters in layer_filters:\n",
        "        # first 3 convolution layers use strides = 2\n",
        "        # last one uses strides = 1\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters=filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=strides,\n",
        "                   padding='same')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    # default output is probability that the image is real\n",
        "    outputs = Dense(1)(x)\n",
        "    if activation is not None:\n",
        "        print(activation)\n",
        "        outputs = Activation(activation)(outputs)\n",
        "\n",
        "    if num_labels:\n",
        "        # ACGAN and InfoGAN have 2nd output\n",
        "        # 2nd output is 10-dim one-hot vector of label\n",
        "        layer = Dense(layer_filters[-2])(x)\n",
        "        labels = Dense(num_labels)(layer)\n",
        "        labels = Activation('softmax', name='label')(labels)\n",
        "        if num_codes is None:\n",
        "            outputs = [outputs, labels]\n",
        "        else:\n",
        "            # InfoGAN have 3rd and 4th outputs\n",
        "            # 3rd output is 1-dim continous Q of 1st c given x\n",
        "            code1 = Dense(1)(layer)\n",
        "            code1 = Activation('sigmoid', name='code1')(code1)\n",
        "\n",
        "            # 4th output is 1-dim continuous Q of 2nd c given x\n",
        "            code2 = Dense(1)(layer)\n",
        "            code2 = Activation('sigmoid', name='code2')(code2)\n",
        "\n",
        "            outputs = [outputs, labels, code1, code2]\n",
        "    elif num_codes is not None:\n",
        "        # StackedGAN Q0 output\n",
        "        # z0_recon is reconstruction of z0 normal distribution\n",
        "        z0_recon =  Dense(num_codes)(x)\n",
        "        z0_recon = Activation('tanh', name='z0')(z0_recon)\n",
        "        outputs = [outputs, z0_recon]\n",
        "\n",
        "    return Model(inputs, outputs, name='discriminator')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOoOHZbwJkiF",
        "colab_type": "text"
      },
      "source": [
        "## Building and Training GAN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIg89es2JliY",
        "colab_type": "text"
      },
      "source": [
        "Due to custom training, the usual fit() function is not going\n",
        "to be used. Instead, train_on_batch() is called up to run a single gradient update for the given batch of data. The generator is then trained via an adversarial network.\n",
        "\n",
        "The training first randomly picks a batch of real images from the dataset. This is labeled as real (1.0). Then, a batch of fake images will be generated by the generator. This is labeled as fake (0.0). The two batches are concatenated and are used to train the discriminator.\n",
        "\n",
        "After this is complete, a new batch of fake images will be generated by the generator and labeled as real (1.0). This batch will be used to train the adversarial network. The two networks are trained alternately for about 40,000 steps. At regular intervals, the generated MNIST digits based on a certain noise vector are saved on the filesystem. At the last training step, the network has converged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt5eunwEJgHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(models, x_train, params):\n",
        "  # the GAN component models\n",
        "  generator, discriminator, adversarial = models\n",
        "\n",
        "  # network parameters\n",
        "  (batch_size, latent_size, n_critic, clip_value, train_steps, model_name) = params\n",
        "\n",
        "  # the generator image is saved every 500 steps\n",
        "  save_interval = 500\n",
        "\n",
        "  # noise vector to see how the generator output evolves during training\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
        "\n",
        "  # number of elements in train dataset\n",
        "  train_size = x_train.shape[0]\n",
        "  # labels for real data\n",
        "  real_labels = np.ones((batch_size, 1))\n",
        "\n",
        "  for i in range(train_steps):\n",
        "    # train discriminator n_critic times\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    for _ in range(n_critic):\n",
        "      ### train the discriminator for 1 batch ###\n",
        "      '''\n",
        "      1 batch of real (label=1.0) and fake images (label=0.0) and randomly pick real images from dataset\n",
        "      '''\n",
        "      rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
        "      real_images = x_train[rand_indexes]\n",
        "\n",
        "      ### generate fake images from noise using generator ###\n",
        "      # generate noise using uniform distribution\n",
        "      noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "\n",
        "      # generate fake images\n",
        "      fake_images = generator.predict(noise)\n",
        "\n",
        "      # train the discriminator network\n",
        "      '''\n",
        "      real data label=1, fake data label=-1 instead of 1 combined batch of real and fake images,\n",
        "      train with 1 batch of real data first, then 1 batch of fake images.\n",
        "      this tweak prevents the gradient from vanishing due to opposite\n",
        "      signs of real and fake data labels (i.e. +1 and -1) and small magnitude of weights due to clipping.\n",
        "      '''\n",
        "      real_loss, real_acc = discriminator.train_on_batch(real_images, real_labels)\n",
        "      fake_loss, fake_acc = discriminator.train_on_batch(fake_images, -real_labels)\n",
        "      # accumulate average loss and accuracy\n",
        "      loss += 0.5 * (real_loss + fake_loss)\n",
        "      acc += 0.5 * (real_acc + fake_acc)\n",
        "\n",
        "      # clip discriminator weights to satisfy Lipschitz constraint\n",
        "      for layer in discriminator.layers:\n",
        "        weights = layer.get_weights()\n",
        "        weights = [np.clip(weight, -clip_value, clip_value) for weight in weights]\n",
        "        layer.set_weights(weights)\n",
        "\n",
        "    # average loss and accuracy per n_critic training iterations\n",
        "    loss /= n_critic\n",
        "    acc /= n_critic\n",
        "    log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "\n",
        "    ### train the adversarial network for 1 batch ###\n",
        "    '''\n",
        "    1 batch of fake images with label=1.0 since the discriminator weights are frozen in adversarial network only the generator is trained\n",
        "    '''\n",
        "    #  generate noise using uniform distribution\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "\n",
        "    ### train the adversarial network ###\n",
        "    ''' \n",
        "    Note that unlike in discriminator training, we do not save the fake images in a variable the fake images go \n",
        "    to the discriminator input of the adversarial for classification\n",
        "    '''\n",
        "    # log the loss and accuracy\n",
        "    loss, acc = adversarial.train_on_batch(noise, real_labels)\n",
        "    log = \"%s [adversarial loss: %f, accuracy: %f]\" % (log, loss, acc)\n",
        "    print(log)\n",
        "\n",
        "    if (i + 1) % save_interval == 0:\n",
        "      # plot generator images on a periodic basis\n",
        "      plot_images(generator, noise_input, show=True, step=(i + 1), model_name=model_name)\n",
        "\n",
        "  '''\n",
        "  save the model after training the generator, the trained generator can be reloaded for future MNIST digit generation\n",
        "  '''\n",
        "  generator.save(model_name + '.h5')\n",
        "\n",
        "def plot_images(generator, noise_input, show=False, step=0, model_name='gan'):\n",
        "  os.makedirs(model_name, exist_ok=True)\n",
        "  filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "  images = generator.predict(noise_input)\n",
        "  plt.figure(figsize=(2.2, 2.2))\n",
        "  num_images = images.shape[0]\n",
        "  image_size = images.shape[1]\n",
        "  rows = int(math.sqrt(noise_input.shape[0]))\n",
        "  for i in range(num_images):\n",
        "      plt.subplot(rows, rows, i + 1)\n",
        "      image = np.reshape(images[i], [image_size, image_size])\n",
        "      plt.imshow(image, cmap='gray')\n",
        "      plt.axis('off')\n",
        "  plt.savefig(filename)\n",
        "  if show:\n",
        "      plt.show()\n",
        "  else:\n",
        "      plt.close('all')\n",
        "\n",
        "def wasserstein_loss(y_label, y_pred):\n",
        "    return -K.mean(y_label * y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goXuz4XWMzbS",
        "colab_type": "text"
      },
      "source": [
        "Now let's build GAN models. Firstly, the discriminator model is built and, following on from that, the generator model is instantiated. The adversarial model is just the generator and the discriminator put together. Across many GANs, the batch size of 64 appears to be the most common."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRB4XOL6MyfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_and_train_models():\n",
        "  # load MNIST dataset\n",
        "  (x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "  # reshape data for CNN as (28, 28, 1) and normalize\n",
        "  image_size = x_train.shape[1]\n",
        "  x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "  x_train = x_train.astype('float32') / 255\n",
        "\n",
        "  model_name = 'lsgan_mnist'\n",
        "\n",
        "  # network parameters, the latent or z vector is 100-dim\n",
        "  latent_size = 100\n",
        "  # hyper parameters from WGAN paper\n",
        "  n_critic = 5\n",
        "  clip_value = 0.01\n",
        "  batch_size = 64\n",
        "  train_steps = 40000\n",
        "  lr = 2e-4\n",
        "  decay = 6e-8\n",
        "  input_shape = (image_size, image_size, 1)\n",
        "\n",
        "  ### build discriminator model ###\n",
        "  inputs = Input(shape=input_shape, name='discriminator_input')\n",
        "  # WGAN uses linear activation in paper\n",
        "  discriminator = build_discriminator(inputs, activation=None)\n",
        "  # original paper uses Adam, but discriminator converges easily with RMSprop\n",
        "  optimizer = RMSprop(learning_rate=lr)\n",
        "  # LSGAN uses MSE loss [2]\n",
        "  discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "  discriminator.summary()\n",
        "\n",
        "  ### build generator model ###\n",
        "  input_shape = (latent_size, )\n",
        "  inputs = Input(shape=input_shape, name='z_input')\n",
        "  generator = build_generator(inputs, image_size)\n",
        "  generator.summary()\n",
        "\n",
        "  ### build adversarial model ###\n",
        "  #  freeze the weights of discriminator during adversarial training\n",
        "  discriminator.trainable = False\n",
        "\n",
        "  # adversarial = generator + discriminator\n",
        "  adversarial = Model(inputs, discriminator(generator(inputs)), name=model_name)\n",
        "  # LSGAN uses MSE loss\n",
        "  adversarial.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "  adversarial.summary()\n",
        "\n",
        "  # train discriminator and adversarial networks\n",
        "  models = (generator, discriminator, adversarial)\n",
        "  params = (batch_size, latent_size, n_critic, clip_value, train_steps, model_name)\n",
        "  train(models, x_train, params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw9h1AbuTt0-",
        "colab_type": "text"
      },
      "source": [
        "The DCGAN models are straightforward. What makes them difficult to build is the fact that small changes in the network design can easily break the training convergence. For example, if batch normalization is used in the discriminator, or if strides = 2 in the generator is transferred to the latter CNN layers, DCGAN will fail to converge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDU8617NT3ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "build_and_train_models()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFBde6cGWs4_",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HTHLeNjVa4Q",
        "colab_type": "code",
        "outputId": "0c30310c-37c5-434f-d6f0-8c285c2ad565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "def test_generator(generator):\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "\n",
        "  plot_images(generator, noise_input=noise_input, show=True, model_name=\"test_outputs\")\n",
        "\n",
        "# load saved model\n",
        "generator = load_model('lsgan_mnist.h5')\n",
        "test_generator(generator)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 158.4x158.4 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpmoWlzdf6L",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAm0Tpeodg0l",
        "colab_type": "text"
      },
      "source": [
        "With the use of MSE or L2, we addressed the twin problems of training the stability and perceptive quality of the GANs."
      ]
    }
  ]
}